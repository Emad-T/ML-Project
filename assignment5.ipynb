{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mohamed Abdelaty     72311\n",
    "###### Emad Toubar               73720\n",
    "###### Abdullah Al labadi       69477\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0 - Reading Data and Saving Different Matrices (same as always)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"Spotify-2000.csv\", index_col=False, thousands=',')\n",
    "except FileNotFoundError:\n",
    "    print(\"Try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Index','Title', 'Artist', 'Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts=df['Top Genre'].value_counts()\n",
    "list_of_genres=list(genre_counts.index.values)\n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(list_of_genres)\n",
    "df['Top Genre']=le.transform(df['Top Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Popularity', axis=1)\n",
    "X=df.drop('Loudness (dB)', axis=1) #Remove this line later\n",
    "y=df['Popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "isPopular = pd.cut(y,bins=[1,50,100], labels=['yes','no'])\n",
    "y = y.to_frame()\n",
    "y.insert(0,'isPopular', isPopular)\n",
    "y.drop('Popularity', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 -  Apply feature scaling using MinMaxScaler to scale your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "X_minmax = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 -  Pick the best two classifiers that you tried on your dataset so far. \n",
    "Using either cross-validation or random splitting, perform\n",
    "classification using each of the classifiers with the scaled features as\n",
    "your input to the classifiers. Report the following performance metrics:\n",
    "training time and accuracy, testing time and accuracy, precision, recall,\n",
    "F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: \n",
      "0.00277094841003418\n",
      "\n",
      "Average Training Accuracy: \n",
      "0.9921014134081284\n",
      "\n",
      "Average Testing Time: \n",
      "0.011138916015625\n",
      "\n",
      "Average Testing Accuracy: \n",
      "0.9899648619035025\n",
      "\n",
      "Average Precision: \n",
      "0.9920369938548494\n",
      "\n",
      "Average Recall: \n",
      "0.9823539076421985\n",
      "\n",
      "Average F1 Score: \n",
      "0.986943370444431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using MinMax with LinearSVC model\n",
    "\n",
    "\n",
    "linearSVC= LinearSVC(dual=False)\n",
    "\n",
    "required_scores = ['precision_macro', 'recall_macro', 'accuracy', 'f1_macro']\n",
    "\n",
    "cv_results_5=cross_validate(linearSVC,X_minmax,y,cv=5, scoring=required_scores, return_train_score = True)\n",
    "\n",
    "\n",
    "#Printing the results:\n",
    "print(\"Average Training Time: \")\n",
    "print(sum(cv_results_5['fit_time'])/5)\n",
    "print()\n",
    "print(\"Average Training Accuracy: \")\n",
    "print(sum(cv_results_5['train_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Testing Time: \")\n",
    "print(sum(cv_results_5['score_time'])/5)\n",
    "print()\n",
    "print(\"Average Testing Accuracy: \")\n",
    "print(sum(cv_results_5['test_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Precision: \")\n",
    "print(sum(cv_results_5['test_precision_macro'])/5)\n",
    "print()\n",
    "print(\"Average Recall: \")\n",
    "print(sum(cv_results_5['test_recall_macro'])/5)\n",
    "print()\n",
    "print(\"Average F1 Score: \")\n",
    "print(sum(cv_results_5['test_f1_macro'])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: \n",
      "0.003210115432739258\n",
      "\n",
      "Average Training Accuracy: \n",
      "1.0\n",
      "\n",
      "Average Testing Time: \n",
      "0.008385324478149414\n",
      "\n",
      "Average Testing Accuracy: \n",
      "1.0\n",
      "\n",
      "Average Precision: \n",
      "1.0\n",
      "\n",
      "Average Recall: \n",
      "1.0\n",
      "\n",
      "Average F1 Score: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Using MinMax with DT Model\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=4, max_depth=5)\n",
    "cv_results_5=cross_validate(clf,X_minmax,y,cv=5, scoring=required_scores, return_train_score = True)\n",
    "\n",
    "#Printing the results:\n",
    "print(\"Average Training Time: \")\n",
    "print(sum(cv_results_5['fit_time'])/5)\n",
    "print()\n",
    "print(\"Average Training Accuracy: \")\n",
    "print(sum(cv_results_5['train_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Testing Time: \")\n",
    "print(sum(cv_results_5['score_time'])/5)\n",
    "print()\n",
    "print(\"Average Testing Accuracy: \")\n",
    "print(sum(cv_results_5['test_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Precision: \")\n",
    "print(sum(cv_results_5['test_precision_macro'])/5)\n",
    "print()\n",
    "print(\"Average Recall: \")\n",
    "print(sum(cv_results_5['test_recall_macro'])/5)\n",
    "print()\n",
    "print(\"Average F1 Score: \")\n",
    "print(sum(cv_results_5['test_f1_macro'])/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3:  Apply feature selection, using either SelectKBest or SelectPercentile, to select the best features to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SelectKBest\n",
    "\n",
    "X_best = SelectKBest(chi2,k=10).fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: \n",
      "0.007454109191894531\n",
      "\n",
      "Average Training Accuracy: \n",
      "0.9907223387622661\n",
      "\n",
      "Average Testing Time: \n",
      "0.006584310531616211\n",
      "\n",
      "Average Testing Accuracy: \n",
      "0.987961108802156\n",
      "\n",
      "Average Precision: \n",
      "0.987003637732451\n",
      "\n",
      "Average Recall: \n",
      "0.9822082144491944\n",
      "\n",
      "Average F1 Score: \n",
      "0.9845001106581492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using SelectKBest with LinearSVC\n",
    "\n",
    "required_scores = ['precision_macro', 'recall_macro', 'accuracy', 'f1_macro']\n",
    "cv_results_5=cross_validate(linearSVC,X_best,y,cv=5, scoring=required_scores, return_train_score = True)\n",
    "\n",
    "#Printing the results:\n",
    "print(\"Average Training Time: \")\n",
    "print(sum(cv_results_5['fit_time'])/5)\n",
    "print()\n",
    "print(\"Average Training Accuracy: \")\n",
    "print(sum(cv_results_5['train_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Testing Time: \")\n",
    "print(sum(cv_results_5['score_time'])/5)\n",
    "print()\n",
    "print(\"Average Testing Accuracy: \")\n",
    "print(sum(cv_results_5['test_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Precision: \")\n",
    "print(sum(cv_results_5['test_precision_macro'])/5)\n",
    "print()\n",
    "print(\"Average Recall: \")\n",
    "print(sum(cv_results_5['test_recall_macro'])/5)\n",
    "print()\n",
    "print(\"Average F1 Score: \")\n",
    "print(sum(cv_results_5['test_f1_macro'])/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: \n",
      "0.004450321197509766\n",
      "\n",
      "Average Training Accuracy: \n",
      "1.0\n",
      "\n",
      "Average Testing Time: \n",
      "0.004597806930541992\n",
      "\n",
      "Average Testing Accuracy: \n",
      "1.0\n",
      "\n",
      "Average Precision: \n",
      "1.0\n",
      "\n",
      "Average Recall: \n",
      "1.0\n",
      "\n",
      "Average F1 Score: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Using SelectKBest with DT\n",
    "\n",
    "cv_results_5=cross_validate(clf,X_best,y,cv=5, scoring=required_scores, return_train_score = True)\n",
    "\n",
    "#Printing the results:\n",
    "print(\"Average Training Time: \")\n",
    "print(sum(cv_results_5['fit_time'])/5)\n",
    "print()\n",
    "print(\"Average Training Accuracy: \")\n",
    "print(sum(cv_results_5['train_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Testing Time: \")\n",
    "print(sum(cv_results_5['score_time'])/5)\n",
    "print()\n",
    "print(\"Average Testing Accuracy: \")\n",
    "print(sum(cv_results_5['test_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Precision: \")\n",
    "print(sum(cv_results_5['test_precision_macro'])/5)\n",
    "print()\n",
    "print(\"Average Recall: \")\n",
    "print(sum(cv_results_5['test_recall_macro'])/5)\n",
    "print()\n",
    "print(\"Average F1 Score: \")\n",
    "print(sum(cv_results_5['test_f1_macro'])/5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Apply PCA on your dataset, print the explained variance by each of the principle components (PCs) and select the first few components that explain most of the variance 70%+ (cumulative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance with  8 components [0.61951817 0.14028684 0.09171071 0.05397781 0.0370653  0.02177575\n",
      " 0.01393661 0.01205195]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components = 8)\n",
    "X_pca = pca.fit(X)\n",
    "print(\"Explained variance with \", 8, \"components\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_with_two = PCA(n_components = 2)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 - Considering the best two classifiers that you tried on your dataset so far and using either cross-validation or random splitting.\n",
    "Perform the classification using each of the classifiers with the first few\n",
    "PCs that explain most of the variance as your input to the\n",
    "classifiers. Report the following performance metrics: training time and\n",
    "accuracy, testing time and accuracy, precision, recall, F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: \n",
      "0.005199813842773437\n",
      "\n",
      "Average Training Accuracy: \n",
      "0.9663996197390027\n",
      "\n",
      "Average Testing Time: \n",
      "0.007047700881958008\n",
      "\n",
      "Average Testing Accuracy: \n",
      "0.9643996926990843\n",
      "\n",
      "Average Precision: \n",
      "0.9543892727406614\n",
      "\n",
      "Average Recall: \n",
      "0.9553695150991303\n",
      "\n",
      "Average F1 Score: \n",
      "0.9546635396290759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\tiger\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "linearSVC= LinearSVC(dual=False)\n",
    "\n",
    "cv_results_5=cross_validate(linearSVC,X_pca,y,cv=5, scoring=required_scores, return_train_score = True)\n",
    "\n",
    "#Printing the results:\n",
    "print(\"Average Training Time: \")\n",
    "print(sum(cv_results_5['fit_time'])/5)\n",
    "print()\n",
    "print(\"Average Training Accuracy: \")\n",
    "print(sum(cv_results_5['train_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Testing Time: \")\n",
    "print(sum(cv_results_5['score_time'])/5)\n",
    "print()\n",
    "print(\"Average Testing Accuracy: \")\n",
    "print(sum(cv_results_5['test_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Precision: \")\n",
    "print(sum(cv_results_5['test_precision_macro'])/5)\n",
    "print()\n",
    "print(\"Average Recall: \")\n",
    "print(sum(cv_results_5['test_recall_macro'])/5)\n",
    "print()\n",
    "print(\"Average F1 Score: \")\n",
    "print(sum(cv_results_5['test_f1_macro'])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: \n",
      "0.005707788467407227\n",
      "\n",
      "Average Training Accuracy: \n",
      "0.957622818802492\n",
      "\n",
      "Average Testing Time: \n",
      "0.008014869689941407\n",
      "\n",
      "Average Testing Accuracy: \n",
      "0.9062241029709952\n",
      "\n",
      "Average Precision: \n",
      "0.8863754993568136\n",
      "\n",
      "Average Recall: \n",
      "0.870178963136761\n",
      "\n",
      "Average F1 Score: \n",
      "0.8774310195543098\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(min_samples_split=4, max_depth=5)\n",
    "cv_results_5=cross_validate(clf,X_pca,y,cv=5, scoring=required_scores, return_train_score = True)\n",
    "\n",
    "#Printing the results:\n",
    "print(\"Average Training Time: \")\n",
    "print(sum(cv_results_5['fit_time'])/5)\n",
    "print()\n",
    "print(\"Average Training Accuracy: \")\n",
    "print(sum(cv_results_5['train_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Testing Time: \")\n",
    "print(sum(cv_results_5['score_time'])/5)\n",
    "print()\n",
    "print(\"Average Testing Accuracy: \")\n",
    "print(sum(cv_results_5['test_accuracy'])/5)\n",
    "print()\n",
    "print(\"Average Precision: \")\n",
    "print(sum(cv_results_5['test_precision_macro'])/5)\n",
    "print()\n",
    "print(\"Average Recall: \")\n",
    "print(sum(cv_results_5['test_recall_macro'])/5)\n",
    "print()\n",
    "print(\"Average F1 Score: \")\n",
    "print(sum(cv_results_5['test_f1_macro'])/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7 - Summarize and discuss your results for each of the classifiers. \n",
    "For example, discuss the impact of feature scaling, selection\n",
    "and dimensionality reduction on your results and running time. Estimate\n",
    "the improvement quantitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultimately, it is evident that our various meterices and accuracies have improved drastically throughout the course of this project. In this report, we performed feature scaling followed by feature selection and finally dimensionality reduction. It is evident that SelectKBest or feature selection led to the best imporvement. For example, it resulted in a near perfect testing score.\n",
    "### This was followed closely by dimensionality reduction which also showed improved metrices. For example, the average testing score here was around 92.3% which is a drastic improvement from the 68% seen with a regular decision tree classifier. \n",
    "### Feature scaling also saw improved results, however they were not as great as those witnessed by feature selection and dimensionality reduction. For example, testing score saw an improvement to around 77% which was better than the intial 68%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
